{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def what_is(x):\n",
    "    if x[0][0] <= 0 and x[0][1] >= 1:\n",
    "        return \"square\"\n",
    "    return \"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_perc = 0.85\n",
    "#load datasets\n",
    "input_s = np.load('square.npy')\n",
    "input_c = np.load('circle.npy')\n",
    "x = np.concatenate([input_s, input_c])\n",
    "y = np.concatenate([np.repeat(np.array([0., 1.])[None, :], len(input_s), axis=0), np.repeat(np.array([1., 0.])[None, :], len(input_c), axis=0)])\n",
    "\n",
    "x, y = unison_shuffled_copies(x,y)\n",
    "train_split = int(train_split_perc * len(x))\n",
    "train_x = x[:train_split]\n",
    "train_y = y[:train_split]\n",
    "\n",
    "test_x = x[train_split:]\n",
    "test_y = y[train_split:]\n",
    "#To see a circle or a square\n",
    "#plt.imshow(input_s[0].reshape(28, 28), cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "#square = 0,1\n",
    "#circle = 1,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 4\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 2 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-a29a2355a871>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=583.011873205\n",
      "Epoch: 0002 cost=113.997090095\n",
      "Epoch: 0003 cost=393.598734199\n",
      "Epoch: 0004 cost=162.409019919\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9060047\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "total_batch = int(len(train_x)/batch_size)\n",
    "sess.run(init)\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "#        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        #mnist batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        batch_x = train_x[batch_size * epoch: (batch_size * epoch) + batch_size]\n",
    "        batch_y = train_y[batch_size * epoch: (batch_size * epoch) + batch_size]\n",
    "        _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n",
    "                                                        Y: batch_y})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Test model\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(\"Accuracy:\", accuracy.eval({X: test_x, Y: test_y},session=sess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './model.ckpt')\n",
    "#restore\n",
    "#sess = tf.Session()\n",
    "#saver = tf.train.Saver()\n",
    "#saver.restore(sess, 'model/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   1  34  80 125 171 217 236  51   0   0   0   0   0   4 221 184\n",
      "  90   9   0   0  22  65  68  68  70 106 152 198 242 255 255 250 211 166\n",
      " 246 133   0   0   0   0   0   0 225 250 255 240 189 219 255 255 255 255\n",
      " 255 255 231 185 139  94  48   6   0   0 199 184   0   0   0   0   0   2\n",
      " 248 129  57 148 193 165 109  58  51  51  51  21   0   0   0   0   0   0\n",
      "   0   0 148 235   0   0   0   0   0  30 255  94   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  97 255  31   0   0   0\n",
      "   0  65 255  60   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  46 255  82   0   0   0   0  98 255  26   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 252 124   0\n",
      "   0   0   0 112 255  10   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 128   0   0   0   0 112 255  10   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 237\n",
      " 146   0   0   0   0 109 255  14   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 183 203   0   0   0   0  77 255  48\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 124 251  12   0   0   0  36 255  89   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  65 255  66   0   0   0   3\n",
      " 247 130   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  11 250 125   0   0   0   0 202 187   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 202 184   0   0\n",
      "   0   0 132 248  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 139 245  14   0   0   0  62 255  73   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  62 255\n",
      "  90   0   0   0   5 241 144   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   1  49 121 194 251 255  74   0   0   0   0 176 214   0\n",
      "   0   0   0   0   0   0   9  30  55  77  98 123 144 169 230 255 252 196\n",
      " 123  50   0   0   0   0   0 105 255 148 130 150 175 196 218 243 255 255\n",
      " 255 255 255 253 232 209 159  86  17   0   0   0   0   0   0   0   0  24\n",
      " 200 234 248 227 204 181 159 136 113  92  69  45  24   3   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2016x2016 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = int(random.random() * len(test_x))\n",
    "x_ = test_x[r]\n",
    "\n",
    "plt.imshow(x_.reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(28,28))\n",
    "y_ = logits.eval(feed_dict={X: [x_]}, session=sess)\n",
    "print(what_is(y_))\n",
    "#plt.show()\n",
    "print(x_)\n",
    "im = Image.fromarray(x_.reshape(28, 28))\n",
    "im.save(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-27d7400aef2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#x_ = im2arr.reshape(784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mwhat_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#test image\n",
    "img = Image.open('circle.png')\n",
    "im2arr = np.array(img)\n",
    "arr_gray = np.zeros([28,28])\n",
    "for x in range(im2arr.shape[0]):\n",
    "    for y in range(im2arr.shape[0]):\n",
    "        v = im2arr[x][y]\n",
    "        g = 0.299 * v[0] + 0.587 * v[1] + 0.114 * v[2]\n",
    "        arr_gray[x][y] = int(g)\n",
    "#print(arr_gray.reshape(784))\n",
    "x_ = arr_gray.reshape(784)\n",
    "#plt.imshow(im2arr, cmap='gray')\n",
    "#plt.show()\n",
    "#x_ = im2arr.reshape(784)\n",
    "y_ = logits.eval(feed_dict={X: [x_]}, session=sess)\n",
    "what_is(y_)\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
